import{_ as n,o as s,c as a,a as t}from"./app.0d31df06.js";const e={},o=t(`<div class="language-python ext-py line-numbers-mode"><pre class="language-python"><code><span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn 
torch<span class="token punctuation">.</span>__version__


<span class="token comment">## Set device type</span>
device <span class="token operator">=</span> <span class="token string">&quot;cuda&quot;</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">&quot;cpu&quot;</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;Using device: </span><span class="token interpolation"><span class="token punctuation">{</span>device<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>

<span class="token comment">## Set the random seed</span>
RANDOM_SEED<span class="token operator">=</span><span class="token number">42</span> 
torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span>seed<span class="token operator">=</span>RANDOM_SEED<span class="token punctuation">)</span> 

<span class="token comment"># Split data into train and test sets</span>
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split
X_train<span class="token punctuation">,</span> X_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span>RANDOM_SEED<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="tensor" tabindex="-1"><a class="header-anchor" href="#tensor" aria-hidden="true">#</a> Tensor</h2><div class="language-python ext-py line-numbers-mode"><pre class="language-python"><code><span class="token comment">## \u7ECF\u5178\u7684 tensor \u521B\u5EFA\u65B9\u6CD5</span>
torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>data<span class="token punctuation">,</span>dtype<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>device<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>requires_grad<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>pin_memory<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>

<span class="token comment">## \u4ECE\u5176\u4ED6\u5F62\u5F0F\u8F6C\u6362\u800C\u6765 \u793A\u4F8B\u53C2\u8003\uFF1Ahttps://pytorch.org/docs/stable/generated/torch.as_tensor.html#torch.as_tensor</span>
torch<span class="token punctuation">.</span>as_tensor<span class="token punctuation">(</span>data<span class="token punctuation">,</span>dtype<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>device<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>ndarray<span class="token punctuation">)</span>

<span class="token comment">## Tensor.ndim</span>
<span class="token comment">## Tensor.shape</span>
torch<span class="token punctuation">.</span>mm<span class="token punctuation">(</span>tensor_A<span class="token punctuation">,</span>tensor_B<span class="token punctuation">)</span>    <span class="token comment">## \u77E9\u9635\u4E58\u6CD5</span>
<span class="token comment">## \u53D8\u5F62</span>
torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> shape<span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>T<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>    <span class="token comment">## \u53EA\u9488\u5BF92D tensor\u8F6C\u7F6E</span>
torch<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> dim0<span class="token punctuation">,</span> dim1<span class="token punctuation">)</span> <span class="token comment">##\u4EA4\u6362\u4E24\u4E2A\u7EF4\u5EA6</span>

torch<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> out<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span> <span class="token comment">## \u53BB\u9664\u90A3\u4E9B\u7EF4\u5EA6\u5927\u5C0F\u4E3A1\u7684\u7EF4\u5EA6</span>
torch<span class="token punctuation">.</span>unbind<span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>		<span class="token comment">## \u53BB\u9664\u67D0\u4E2A\u7EF4\u5EA6</span>
torch<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> dim<span class="token punctuation">,</span> out<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span>		<span class="token comment">## \u5728\u6307\u5B9A\u4F4D\u7F6E\u6DFB\u52A0\u7EF4\u5EA6\u3002</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="loss-and-optimizer" tabindex="-1"><a class="header-anchor" href="#loss-and-optimizer" aria-hidden="true">#</a> Loss And Optimizer</h2><ul><li>PyTorch\u5728 <code>torch.nn</code> \u4E2D\u6709\u5F88\u591A\u5185\u7F6E\u7684\u635F\u5931\u51FD\u6570\u3002</li><li><code>torch.optim</code> \u4E2D\u627E\u5230\u5404\u79CD\u4F18\u5316\u51FD\u6570\u5B9E\u73B0\u3002</li></ul><div class="language-python ext-py line-numbers-mode"><pre class="language-python"><code><span class="token comment"># Create the loss function</span>
loss_fn <span class="token operator">=</span> nn<span class="token punctuation">.</span>L1Loss<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># MAE loss is same as L1Loss</span>

<span class="token comment"># Create the optimizer</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>params<span class="token operator">=</span>model_0<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment"># parameters of target model to optimize</span>
                            lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span> <span class="token comment"># learning rate (how much the optimizer should change parameters at each step, higher=more (less stable), lower=less (might take a long time))</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>trainng</li></ul><img src="https://cdn.jsdelivr.net/gh/crush598/image@main/AI202302121620749.png" alt="01-pytorch-training-loop-annotated" style="zoom:50%;"><ul><li>testing</li></ul><img src="https://cdn.jsdelivr.net/gh/crush598/image@main/AI202302121620559.png" alt="01-pytorch-testing-loop-annotated" style="zoom:50%;"><h2 id="save-and-load" tabindex="-1"><a class="header-anchor" href="#save-and-load" aria-hidden="true">#</a> Save And Load</h2><ul><li>torch.save()</li></ul><div class="language-python ext-py line-numbers-mode"><pre class="language-python"><code><span class="token keyword">from</span> pathlib <span class="token keyword">import</span> Path

<span class="token comment"># 1. Create models directory </span>
MODEL_PATH <span class="token operator">=</span> Path<span class="token punctuation">(</span><span class="token string">&quot;models&quot;</span><span class="token punctuation">)</span>
MODEL_PATH<span class="token punctuation">.</span>mkdir<span class="token punctuation">(</span>parents<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> exist_ok<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment"># 2. Create model save path </span>
MODEL_NAME <span class="token operator">=</span> <span class="token string">&quot;01_pytorch_workflow_model_0.pth&quot;</span>
MODEL_SAVE_PATH <span class="token operator">=</span> MODEL_PATH <span class="token operator">/</span> MODEL_NAME

<span class="token comment"># 3. Save the model state dict </span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;Saving model to: </span><span class="token interpolation"><span class="token punctuation">{</span>MODEL_SAVE_PATH<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>obj<span class="token operator">=</span>model_0<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment"># only saving the state_dict() only saves the models learned parameters</span>
           f<span class="token operator">=</span>MODEL_SAVE_PATH<span class="token punctuation">)</span> 
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>Torch.load()</li></ul><div class="language-python ext-py line-numbers-mode"><pre class="language-python"><code><span class="token comment"># Instantiate a fresh instance of LinearRegressionModelV2</span>
loaded_model_1 <span class="token operator">=</span> LinearRegressionModelV2<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># Load model state dict </span>
loaded_model_1<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>MODEL_SAVE_PATH<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># Put model to target device (if your data is on GPU, model will have to be on GPU to make predictions)</span>
loaded_model_1<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;Loaded model:\\n</span><span class="token interpolation"><span class="token punctuation">{</span>loaded_model_1<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;Model on device:\\n</span><span class="token interpolation"><span class="token punctuation">{</span><span class="token builtin">next</span><span class="token punctuation">(</span>loaded_model_1<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>device<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,15),p=[o];function c(i,l){return s(),a("div",null,p)}var r=n(e,[["render",c],["__file","2023-01-17-Pytorch.html.vue"]]);export{r as default};
