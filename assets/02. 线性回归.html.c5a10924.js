const t=JSON.parse('{"key":"v-c10380aa","path":"/posts/02.%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%88%9D%E5%AD%A6%E8%80%85/02.%20%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92.html","title":"线性回归","lang":"zh-CN","frontmatter":{"title":"线性回归","date":"2022-10-15T18:49:16.000Z","category":["AI"],"tag":["机器学习"],"summary":"线性回归 线性回归算法简介 线性回归是通过属性的线性组合来进行预测的函数，即 ​\\t$f(x) = w1x1 + w2x2 + ...+ wnxn + b$ ，使得 $f(xi) \\\\simeq yi$ 用向量形式表示为 $$f(x) = w^Tx + b$$ 离散属性的处理：若有序，则连续化；否则，转化为 K 维向量 参数估计--最小二乘法 确定 w 和 b ","head":[["meta",{"property":"og:url","content":"https://crush598-github-io.vercel.app/posts/02.%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%88%9D%E5%AD%A6%E8%80%85/02.%20%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92.html"}],["meta",{"property":"og:site_name","content":"Hush-note"}],["meta",{"property":"og:title","content":"线性回归"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:locale:alternate","content":"en-US"}],["meta",{"property":"article:tag","content":"机器学习"}],["meta",{"property":"article:published_time","content":"2022-10-15T18:49:16.000Z"}],["link",{"rel":"alternate","hreflang":"en-us","href":"https://crush598-github-io.vercel.app/en/posts/02.%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%88%9D%E5%AD%A6%E8%80%85/02.%20%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92.html"}]]},"excerpt":"","headers":[{"level":2,"title":"线性回归算法简介","slug":"线性回归算法简介","link":"#线性回归算法简介","children":[]},{"level":2,"title":"参数估计--最小二乘法","slug":"参数估计-最小二乘法","link":"#参数估计-最小二乘法","children":[]},{"level":2,"title":"广义线性模型","slug":"广义线性模型","link":"#广义线性模型","children":[]}],"git":{},"readingTime":{"minutes":1.53,"words":458},"copyright":"著作权归所有\\n原文链接：https://crush598-github-io.vercel.app/posts/02.%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%88%9D%E5%AD%A6%E8%80%85/02.%20%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92.html","filePathRelative":"posts/02. 机器学习初学者/02. 线性回归.md","localizedDate":"2022年10月16日"}');export{t as data};
