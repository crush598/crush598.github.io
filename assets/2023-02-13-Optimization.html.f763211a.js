const e=JSON.parse('{"key":"v-577ba89b","path":"/Knowledge/AI/2023-02-13-Optimization.html","title":"Optimization","lang":"en-US","frontmatter":{"title":"Optimization","date":"2023-02-13T00:00:00.000Z"},"excerpt":"","headers":[{"level":2,"title":"SGD (stochastic gradient descent)","slug":"sgd-stochastic-gradient-descent","children":[]},{"level":2,"title":"SGD with momentum(SGDM)","slug":"sgd-with-momentum-sgdm","children":[]},{"level":2,"title":"Adagrad(Adaptive Gradient Descent)","slug":"adagrad-adaptive-gradient-descent","children":[]},{"level":2,"title":"RMSProp\uFF08Root Mean Square Propagation\uFF09","slug":"rmsprop-root-mean-square-propagation","children":[]},{"level":2,"title":"Adam\uFF08Adaptive Moment Estimation\uFF09","slug":"adam-adaptive-moment-estimation","children":[]},{"level":2,"title":"learning rate decay","slug":"learning-rate-decay","children":[]},{"level":2,"title":"warm up","slug":"warm-up","children":[]},{"level":2,"title":"early stopping","slug":"early-stopping","children":[]}],"git":{},"readingTime":{"minutes":3,"words":694},"filePathRelative":"Knowledge/AI/2023-02-13-Optimization.md"}');export{e as data};
