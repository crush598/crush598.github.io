const e=JSON.parse('{"key":"v-18021427","path":"/posts/02.%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%88%9D%E5%AD%A6%E8%80%85/04.%20%E5%86%B3%E7%AD%96%E6%A0%91.html","title":"决策树","lang":"zh-CN","frontmatter":{"title":"决策树","date":"2022-10-16T21:02:05.000Z","category":["AI"],"tag":["机器学习"],"description":"决策树 决策树简介 决策树（Decision tree）是基于已知各种情况（特征取值）的基础上，通过构建树型决策结构来进行分析的一种方式，是常用的有监督的分类算法。 决策树学习通常包括 3 个步骤：特征选择、决策树的生成和决策树的修剪 特征选择 决策树的关键在于：选取最优划分属性。一般而言，我们希望随着决策树的划分过程，决策树的分支结点所包含的样本尽可能属于同一类别，即结点的纯度越来越高。","head":[["meta",{"property":"og:url","content":"https://crush598.github.io/posts/02.%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%88%9D%E5%AD%A6%E8%80%85/04.%20%E5%86%B3%E7%AD%96%E6%A0%91.html"}],["meta",{"property":"og:site_name","content":"Hush"}],["meta",{"property":"og:title","content":"决策树"}],["meta",{"property":"og:description","content":"决策树 决策树简介 决策树（Decision tree）是基于已知各种情况（特征取值）的基础上，通过构建树型决策结构来进行分析的一种方式，是常用的有监督的分类算法。 决策树学习通常包括 3 个步骤：特征选择、决策树的生成和决策树的修剪 特征选择 决策树的关键在于：选取最优划分属性。一般而言，我们希望随着决策树的划分过程，决策树的分支结点所包含的样本尽可能属于同一类别，即结点的纯度越来越高。"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:locale:alternate","content":"en-US"}],["meta",{"property":"article:tag","content":"机器学习"}],["meta",{"property":"article:published_time","content":"2022-10-16T21:02:05.000Z"}],["link",{"rel":"alternate","hreflang":"en-us","href":"https://crush598.github.io/en/posts/02.%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%88%9D%E5%AD%A6%E8%80%85/04.%20%E5%86%B3%E7%AD%96%E6%A0%91.html"}]]},"headers":[{"level":2,"title":"决策树简介","slug":"决策树简介","link":"#决策树简介","children":[]},{"level":2,"title":"特征选择","slug":"特征选择","link":"#特征选择","children":[{"level":3,"title":"（1）信息熵","slug":"_1-信息熵","link":"#_1-信息熵","children":[]},{"level":3,"title":"（2）信息增益","slug":"_2-信息增益","link":"#_2-信息增益","children":[]},{"level":3,"title":"（3）信息增益率","slug":"_3-信息增益率","link":"#_3-信息增益率","children":[]},{"level":3,"title":"（4）基尼指数","slug":"_4-基尼指数","link":"#_4-基尼指数","children":[]}]},{"level":2,"title":"决策树的生成","slug":"决策树的生成","link":"#决策树的生成","children":[]},{"level":2,"title":"决策树的剪枝","slug":"决策树的剪枝","link":"#决策树的剪枝","children":[]},{"level":2,"title":"连续与缺失值","slug":"连续与缺失值","link":"#连续与缺失值","children":[]}],"git":{},"readingTime":{"minutes":4.37,"words":1311},"localizedDate":"2022年10月17日","filePathRelative":"posts/02. 机器学习初学者/04. 决策树.md","excerpt":"<h1> 决策树</h1>\\n<h2> 决策树简介</h2>\\n<p>决策树（Decision tree）是基于已知各种情况（特征取值）的基础上，通过构建树型决策结构来进行分析的一种方式，是常用的有监督的分类算法。</p>\\n<p>决策树学习通常包括 3 个步骤：特征选择、决策树的生成和决策树的修剪</p>\\n<img src=\\"https://cdn.jsdelivr.net/gh/crush598/image@main/AI/202210181045434.png\\" alt=\\"决策树的发展史\\" style=\\"zoom:50%;\\">\\n<h2> 特征选择</h2>\\n<p>决策树的关键在于：<strong>选取最优划分属性</strong>。一般而言，我们希望随着决策树的划分过程，<strong>决策树的分支结点所包含的样本尽可能属于同一类别，即结点的纯度越来越高</strong>。</p>","copyright":{"author":"Hush"},"autoDesc":true}');export{e as data};
