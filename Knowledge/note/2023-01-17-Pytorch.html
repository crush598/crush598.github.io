<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <meta name="generator" content="VuePress 2.0.0-beta.49">
    <style>
      :root {
        --c-bg: #fff;
      }
      html.dark {
        --c-bg: #22272e;
      }
      html, body {
        background-color: var(--c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem('vuepress-color-scheme');
			const systemDarkMode = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;
			if (userMode === 'dark' || (userMode !== 'light' && systemDarkMode)) {
				document.documentElement.classList.toggle('dark', true);
			}
    </script>
    <title>Pytorch | Hush</title><meta name="description" content="UP && UP">
    <link rel="modulepreload" href="/assets/app.aed97a80.js"><link rel="modulepreload" href="/assets/2023-01-17-Pytorch.html.6fc2c788.js"><link rel="modulepreload" href="/assets/2023-01-17-Pytorch.html.144a1f43.js"><link rel="prefetch" href="/assets/about.html.7f10632c.js"><link rel="prefetch" href="/assets/board.html.1079699a.js"><link rel="prefetch" href="/assets/links.html.4f889e50.js"><link rel="prefetch" href="/assets/index.html.199c3cd2.js"><link rel="prefetch" href="/assets/index.html.87beabb9.js"><link rel="prefetch" href="/assets/index.html.daca2548.js"><link rel="prefetch" href="/assets/index.html.af1e35c5.js"><link rel="prefetch" href="/assets/index.html.1605a86e.js"><link rel="prefetch" href="/assets/index.html.a6ebc76e.js"><link rel="prefetch" href="/assets/index.html.c5a6edf3.js"><link rel="prefetch" href="/assets/index.html.f02a0705.js"><link rel="prefetch" href="/assets/index.html.07bffb93.js"><link rel="prefetch" href="/assets/index.html.55dc2d5a.js"><link rel="prefetch" href="/assets/index.html.cb796310.js"><link rel="prefetch" href="/assets/index.html.97fc1f8e.js"><link rel="prefetch" href="/assets/index.html.efdcba74.js"><link rel="prefetch" href="/assets/index.html.2c88baf2.js"><link rel="prefetch" href="/assets/论文结构.html.cb2502d5.js"><link rel="prefetch" href="/assets/01.Git Pro.html.eeb032dd.js"><link rel="prefetch" href="/assets/03.Python 随记.html.29339562.js"><link rel="prefetch" href="/assets/2023-1-8-Lanqiao.html.396ee16b.js"><link rel="prefetch" href="/assets/Numpy 小记.html.7b52f7d4.js"><link rel="prefetch" href="/assets/Pandas 小记.html.4d016cab.js"><link rel="prefetch" href="/assets/02.Linear regression.html.42d557ac.js"><link rel="prefetch" href="/assets/03.Logistic regression.html.dd6dabea.js"><link rel="prefetch" href="/assets/04.Decision tree.html.2d4e2754.js"><link rel="prefetch" href="/assets/05.Support vector machine.html.3a350b0d.js"><link rel="prefetch" href="/assets/06.Feedforward neural network.html.48f22313.js"><link rel="prefetch" href="/assets/07.集成学习.html.4ac54434.js"><link rel="prefetch" href="/assets/08.聚类.html.a9dc3746.js"><link rel="prefetch" href="/assets/09.杂文.html.db51afdd.js"><link rel="prefetch" href="/assets/2023-01-09-CNN.html.3289c0df.js"><link rel="prefetch" href="/assets/2023-02-13-Bias-_-Variance.html.cf21f0dd.js"><link rel="prefetch" href="/assets/2023-02-13-Optimization.html.f763211a.js"><link rel="prefetch" href="/assets/2023-01-09-AlexNet.html.81d1ea0e.js"><link rel="prefetch" href="/assets/404.html.7c518b82.js"><link rel="prefetch" href="/assets/index.html.28fa388e.js"><link rel="prefetch" href="/assets/index.html.271c9982.js"><link rel="prefetch" href="/assets/index.html.a84118f6.js"><link rel="prefetch" href="/assets/index.html.0029a7ad.js"><link rel="prefetch" href="/assets/index.html.ffe7e9b0.js"><link rel="prefetch" href="/assets/index.html.db57d449.js"><link rel="prefetch" href="/assets/index.html.453c9aca.js"><link rel="prefetch" href="/assets/index.html.46e5b51a.js"><link rel="prefetch" href="/assets/index.html.2666400f.js"><link rel="prefetch" href="/assets/index.html.92d483a2.js"><link rel="prefetch" href="/assets/index.html.26a0f2a1.js"><link rel="prefetch" href="/assets/index.html.e07d945d.js"><link rel="prefetch" href="/assets/index.html.b21d3d43.js"><link rel="prefetch" href="/assets/about.html.f7967688.js"><link rel="prefetch" href="/assets/board.html.343ff854.js"><link rel="prefetch" href="/assets/links.html.d26112ea.js"><link rel="prefetch" href="/assets/index.html.43748476.js"><link rel="prefetch" href="/assets/index.html.5210d8bf.js"><link rel="prefetch" href="/assets/index.html.91723c75.js"><link rel="prefetch" href="/assets/index.html.b7fd9515.js"><link rel="prefetch" href="/assets/index.html.30196ab8.js"><link rel="prefetch" href="/assets/index.html.800dc862.js"><link rel="prefetch" href="/assets/index.html.ede42691.js"><link rel="prefetch" href="/assets/index.html.98f22eca.js"><link rel="prefetch" href="/assets/index.html.f621b9c2.js"><link rel="prefetch" href="/assets/index.html.a0e3c066.js"><link rel="prefetch" href="/assets/index.html.3155e20c.js"><link rel="prefetch" href="/assets/index.html.98692a88.js"><link rel="prefetch" href="/assets/index.html.731dfefb.js"><link rel="prefetch" href="/assets/index.html.7d37e05e.js"><link rel="prefetch" href="/assets/论文结构.html.9d343fac.js"><link rel="prefetch" href="/assets/01.Git Pro.html.831a66fc.js"><link rel="prefetch" href="/assets/03.Python 随记.html.ee3d8084.js"><link rel="prefetch" href="/assets/2023-1-8-Lanqiao.html.6e302005.js"><link rel="prefetch" href="/assets/Numpy 小记.html.efc09d7f.js"><link rel="prefetch" href="/assets/Pandas 小记.html.9aa58d51.js"><link rel="prefetch" href="/assets/02.Linear regression.html.3b948a8e.js"><link rel="prefetch" href="/assets/03.Logistic regression.html.8d3b509d.js"><link rel="prefetch" href="/assets/04.Decision tree.html.f643de50.js"><link rel="prefetch" href="/assets/05.Support vector machine.html.1b29df90.js"><link rel="prefetch" href="/assets/06.Feedforward neural network.html.5871bd42.js"><link rel="prefetch" href="/assets/07.集成学习.html.45ffb718.js"><link rel="prefetch" href="/assets/08.聚类.html.f7f02495.js"><link rel="prefetch" href="/assets/09.杂文.html.24b8af3f.js"><link rel="prefetch" href="/assets/2023-01-09-CNN.html.b2040c7c.js"><link rel="prefetch" href="/assets/2023-02-13-Bias-_-Variance.html.6a3664f2.js"><link rel="prefetch" href="/assets/2023-02-13-Optimization.html.ffddde70.js"><link rel="prefetch" href="/assets/2023-01-09-AlexNet.html.10ce7d27.js"><link rel="prefetch" href="/assets/404.html.173db82f.js"><link rel="prefetch" href="/assets/index.html.e8b3ec56.js"><link rel="prefetch" href="/assets/index.html.4ef9708c.js"><link rel="prefetch" href="/assets/index.html.bce376a1.js"><link rel="prefetch" href="/assets/index.html.4cf93d48.js"><link rel="prefetch" href="/assets/index.html.23cb5563.js"><link rel="prefetch" href="/assets/index.html.1fdee51f.js"><link rel="prefetch" href="/assets/index.html.e494b11d.js"><link rel="prefetch" href="/assets/index.html.dad6c800.js"><link rel="prefetch" href="/assets/index.html.308b6391.js"><link rel="prefetch" href="/assets/index.html.7a5f255d.js"><link rel="prefetch" href="/assets/index.html.c819c1d9.js"><link rel="prefetch" href="/assets/index.html.b9fbf674.js"><link rel="prefetch" href="/assets/index.html.91e01ef7.js"><link rel="prefetch" href="/assets/404.5ce20b75.js"><link rel="prefetch" href="/assets/HomePage.915d9452.js"><link rel="prefetch" href="/assets/Layout.c775e847.js"><link rel="prefetch" href="/assets/Links.18ec50d6.js"><link rel="prefetch" href="/assets/Post.d0153f5c.js"><link rel="prefetch" href="/assets/Tags.71009f19.js">
    <link rel="stylesheet" href="/assets/style.5ec59d18.css">
  </head>
  <body>
    <div id="app"><!--[--><div class="theme-container"><!--[--><header class="navbar is-fixed is-visible invert"><span><a href="/" class=""><span class="site-name">Hush-Note</span></a></span><div class="navbar-items-wrapper" style=""><!--[--><!--]--><nav class="navbar-items can-hide"><!--[--><div class="navbar-item"><a href="/" class="" aria-label="Home"><!--[--><!--]--><span class="nav-icon"><svg class="ov-icon" style="font-size:1.2em;" aria-hidden="true" width="19.2" height="19.2" viewbox="-43.52 -43.52 599.04 599.04" fill="currentColor"><path d="M489.2 287.9h-27.4c-2.6 0-4.6 2-4.6 4.6v32h-36.6V146.2c0-2.6-2-4.6-4.6-4.6h-27.4c-2.6 0-4.6 2-4.6 4.6v32h-36.6v-32c0-2.6-2-4.6-4.6-4.6h-27.4c-2.6 0-4.6 2-4.6 4.6v32h-36.6v-32c0-6-8-4.6-11.7-4.6v-38c8.3-2 17.1-3.4 25.7-3.4 10.9 0 20.9 4.3 31.4 4.3 4.6 0 27.7-1.1 27.7-8v-60c0-2.6-2-4.6-4.6-4.6-5.1 0-15.1 4.3-24 4.3-9.7 0-20.9-4.3-32.6-4.3-8 0-16 1.1-23.7 2.9v-4.9c5.4-2.6 9.1-8.3 9.1-14.3 0-20.7-31.4-20.8-31.4 0 0 6 3.7 11.7 9.1 14.3v111.7c-3.7 0-11.7-1.4-11.7 4.6v32h-36.6v-32c0-2.6-2-4.6-4.6-4.6h-27.4c-2.6 0-4.6 2-4.6 4.6v32H128v-32c0-2.6-2-4.6-4.6-4.6H96c-2.6 0-4.6 2-4.6 4.6v178.3H54.8v-32c0-2.6-2-4.6-4.6-4.6H22.8c-2.6 0-4.6 2-4.6 4.6V512h182.9v-96c0-72.6 109.7-72.6 109.7 0v96h182.9V292.5c.1-2.6-1.9-4.6-4.5-4.6zm-288.1-4.5c0 2.6-2 4.6-4.6 4.6h-27.4c-2.6 0-4.6-2-4.6-4.6v-64c0-2.6 2-4.6 4.6-4.6h27.4c2.6 0 4.6 2 4.6 4.6v64zm146.4 0c0 2.6-2 4.6-4.6 4.6h-27.4c-2.6 0-4.6-2-4.6-4.6v-64c0-2.6 2-4.6 4.6-4.6h27.4c2.6 0 4.6 2 4.6 4.6v64z"/></svg></span><span>Home</span><!--[--><!--]--></a></div><div class="navbar-item"><a href="/Knowledge/AI/02.Linear regression.md" class="" aria-label="AI"><!--[--><!--]--><span class="nav-icon"><svg class="ov-icon" style="font-size:1.2em;" aria-hidden="true" width="19.2" height="19.2" viewbox="-1.6 -1.6 19.2 19.2" fill="currentColor"><path d="M6 12.5a.5.5 0 01.5-.5h3a.5.5 0 010 1h-3a.5.5 0 01-.5-.5zM3 8.062C3 6.76 4.235 5.765 5.53 5.886a26.58 26.58 0 004.94 0C11.765 5.765 13 6.76 13 8.062v1.157a.933.933 0 01-.765.935c-.845.147-2.34.346-4.235.346-1.895 0-3.39-.2-4.235-.346A.933.933 0 013 9.219V8.062zm4.542-.827a.25.25 0 00-.217.068l-.92.9a24.767 24.767 0 01-1.871-.183.25.25 0 00-.068.495c.55.076 1.232.149 2.02.193a.25.25 0 00.189-.071l.754-.736.847 1.71a.25.25 0 00.404.062l.932-.97a25.286 25.286 0 001.922-.188.25.25 0 00-.068-.495c-.538.074-1.207.145-1.98.189a.25.25 0 00-.166.076l-.754.785-.842-1.7a.25.25 0 00-.182-.135z"/><path d="M8.5 1.866a1 1 0 10-1 0V3h-2A4.5 4.5 0 001 7.5V8a1 1 0 00-1 1v2a1 1 0 001 1v1a2 2 0 002 2h10a2 2 0 002-2v-1a1 1 0 001-1V9a1 1 0 00-1-1v-.5A4.5 4.5 0 0010.5 3h-2V1.866zM14 7.5V13a1 1 0 01-1 1H3a1 1 0 01-1-1V7.5A3.5 3.5 0 015.5 4h5A3.5 3.5 0 0114 7.5z"/></svg></span><span>AI</span><!--[--><!--]--></a></div><div class="navbar-item"><a href="/Knowledge/note/01.Git Pro.md" class="" aria-label="Note"><!--[--><!--]--><span class="nav-icon"><svg class="ov-icon" style="font-size:1.2em;" aria-hidden="true" width="19.2" height="19.2" viewbox="0 0 512 512" fill="currentColor"><path d="M48 322.3V189.7A29.74 29.74 0 0177.7 160h137.44l24.4-32H77.7A61.77 61.77 0 0016 189.7v132.6A61.77 61.77 0 0077.7 384h96.85a22.57 22.57 0 01.26-7.32l.15-.75.21-.73 6.5-23.2H77.7A29.74 29.74 0 0148 322.3zM386.3 128h-98.64a22.69 22.69 0 01-.27 7.2l-.15.74-.21.73-6.54 23.33H386.3a29.74 29.74 0 0129.7 29.7v132.6a29.74 29.74 0 01-29.7 29.7H247l-24.42 32H386.3a61.77 61.77 0 0061.7-61.7V189.7a61.77 61.77 0 00-61.7-61.7z"/><path d="M162.65 294.16a24.37 24.37 0 01-21.56-13 25 25 0 011.42-25.83l.31-.46.33-.44L197.62 183H89.69a20 20 0 00-20 20v106a20 20 0 0020 20h98.42l9.78-34.86z"/><path d="M276.07 280.89l27.07-35.49a5.2 5.2 0 00.77-1.91 5 5 0 00.08-.66 5 5 0 00-.08-1.29 5.11 5.11 0 00-.68-1.75 4.76 4.76 0 00-.78-.95 3.48 3.48 0 00-.48-.38 4 4 0 00-1.11-.55 4.28 4.28 0 00-1.31-.2h-61.62l12.12-43.21 3.23-11.5 6.21-22.16.51-1.84 7.79-27.76a3.51 3.51 0 00.05-.55v-.16c0-.05 0-.26-.05-.38s0-.09 0-.14a2.2 2.2 0 00-.17-.45 3.77 3.77 0 00-.26-.39l-.09-.1a2.73 2.73 0 00-.25-.23l-.1-.08a3.14 3.14 0 00-.39-.24 2 2 0 00-.41-.14H265.53a2.3 2.3 0 00-.45 0 1.9 1.9 0 00-.42.15l-.13.07-.3.21-.11.1a2.4 2.4 0 00-.36.41l-18 23.63-13.14 17.22-9.85 12.83-63.71 83.55a5.72 5.72 0 00-.44.8 4.78 4.78 0 00-.35 1.09 4.7 4.7 0 00-.08 1.29 4.86 4.86 0 002 3.71 4.74 4.74 0 00.54.31 4.31 4.31 0 001.89.43h61.62L194.42 380.6a3.64 3.64 0 000 .56v.15a2.32 2.32 0 00.06.38.58.58 0 000 .14 2.2 2.2 0 00.17.45 3.62 3.62 0 00.26.38l.09.1.25.24a.39.39 0 01.1.08 2.22 2.22 0 00.39.23 2.83 2.83 0 00.41.14h.13a1.86 1.86 0 00.33 0h.13a2.32 2.32 0 00.45-.06 2.05 2.05 0 00.41-.16l.13-.07.3-.21.11-.09a2.4 2.4 0 00.36-.41L221.82 352l17.53-23z"/><path d="M319.5 256.93l-.46.6L264.51 329h109.8a20 20 0 0020-20V203a20 20 0 00-20-20H274.05l-9.74 34.73h35.24A24.35 24.35 0 01321 230.5a25.21 25.21 0 01-1 25.79zM480 202.67a16 16 0 00-16 16v74.66a16 16 0 0032 0v-74.66a16 16 0 00-16-16z"/></svg></span><span>Note</span><!--[--><!--]--></a></div><div class="navbar-item"><a href="/tags/" class="" aria-label="Tags"><!--[--><!--]--><span class="nav-icon"><svg class="ov-icon" style="font-size:1.2em;" aria-hidden="true" width="19.2" height="19.2" viewbox="-43.52 -43.52 599.04 599.04" fill="currentColor"><path d="M0 252.118V48C0 21.49 21.49 0 48 0h204.118a48 48 0 0133.941 14.059l211.882 211.882c18.745 18.745 18.745 49.137 0 67.882L293.823 497.941c-18.745 18.745-49.137 18.745-67.882 0L14.059 286.059A48 48 0 010 252.118zM112 64c-26.51 0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48z"/></svg></span><span>Tags</span><!--[--><!--]--></a></div><div class="navbar-item"><a href="/about/board.md" class="" aria-label="Board"><!--[--><!--]--><span class="nav-icon"><svg class="ov-icon" style="font-size:1.2em;" aria-hidden="true" width="19.2" height="19.2" viewbox="-1.6 -1.6 19.2 19.2" fill="currentColor"><path d="M4 11a1 1 0 112 0v1a1 1 0 11-2 0v-1zm6-4a1 1 0 112 0v5a1 1 0 11-2 0V7zM7 9a1 1 0 012 0v3a1 1 0 11-2 0V9z"/><path d="M4 1.5H3a2 2 0 00-2 2V14a2 2 0 002 2h10a2 2 0 002-2V3.5a2 2 0 00-2-2h-1v1h1a1 1 0 011 1V14a1 1 0 01-1 1H3a1 1 0 01-1-1V3.5a1 1 0 011-1h1v-1z"/><path d="M9.5 1a.5.5 0 01.5.5v1a.5.5 0 01-.5.5h-3a.5.5 0 01-.5-.5v-1a.5.5 0 01.5-.5h3zm-3-1A1.5 1.5 0 005 1.5v1A1.5 1.5 0 006.5 4h3A1.5 1.5 0 0011 2.5v-1A1.5 1.5 0 009.5 0h-3z"/></svg></span><span>Board</span><!--[--><!--]--></a></div><!--]--><div class="navbar-item"><a style="cursor:pointer;"><span class="nav-icon"><svg class="ov-icon" style="font-size:1.2em;" aria-hidden="true" width="19.2" height="19.2" viewbox="0 0 24 24" fill="currentColor"><path fill="none" d="M0 0h24v24H0z"/><path d="M11 2c4.968 0 9 4.032 9 9s-4.032 9-9 9-9-4.032-9-9 4.032-9 9-9zm0 16c3.867 0 7-3.133 7-7 0-3.868-3.133-7-7-7-3.868 0-7 3.132-7 7 0 3.867 3.132 7 7 7zm8.485.071l2.829 2.828-1.415 1.415-2.828-2.829 1.414-1.414z"/></svg></span><span>Search</span></a></div></nav><!--[--><!--]--><!----></div></header><!--]--><div class="sidebar-mask"></div><!--[--><aside class="sidebar"><nav class="navbar-items"><!--[--><div class="navbar-item"><a href="/" class="" aria-label="Home"><!--[--><!--]--><span class="nav-icon"><svg class="ov-icon" style="font-size:1.2em;" aria-hidden="true" width="19.2" height="19.2" viewbox="-43.52 -43.52 599.04 599.04" fill="currentColor"><path d="M489.2 287.9h-27.4c-2.6 0-4.6 2-4.6 4.6v32h-36.6V146.2c0-2.6-2-4.6-4.6-4.6h-27.4c-2.6 0-4.6 2-4.6 4.6v32h-36.6v-32c0-2.6-2-4.6-4.6-4.6h-27.4c-2.6 0-4.6 2-4.6 4.6v32h-36.6v-32c0-6-8-4.6-11.7-4.6v-38c8.3-2 17.1-3.4 25.7-3.4 10.9 0 20.9 4.3 31.4 4.3 4.6 0 27.7-1.1 27.7-8v-60c0-2.6-2-4.6-4.6-4.6-5.1 0-15.1 4.3-24 4.3-9.7 0-20.9-4.3-32.6-4.3-8 0-16 1.1-23.7 2.9v-4.9c5.4-2.6 9.1-8.3 9.1-14.3 0-20.7-31.4-20.8-31.4 0 0 6 3.7 11.7 9.1 14.3v111.7c-3.7 0-11.7-1.4-11.7 4.6v32h-36.6v-32c0-2.6-2-4.6-4.6-4.6h-27.4c-2.6 0-4.6 2-4.6 4.6v32H128v-32c0-2.6-2-4.6-4.6-4.6H96c-2.6 0-4.6 2-4.6 4.6v178.3H54.8v-32c0-2.6-2-4.6-4.6-4.6H22.8c-2.6 0-4.6 2-4.6 4.6V512h182.9v-96c0-72.6 109.7-72.6 109.7 0v96h182.9V292.5c.1-2.6-1.9-4.6-4.5-4.6zm-288.1-4.5c0 2.6-2 4.6-4.6 4.6h-27.4c-2.6 0-4.6-2-4.6-4.6v-64c0-2.6 2-4.6 4.6-4.6h27.4c2.6 0 4.6 2 4.6 4.6v64zm146.4 0c0 2.6-2 4.6-4.6 4.6h-27.4c-2.6 0-4.6-2-4.6-4.6v-64c0-2.6 2-4.6 4.6-4.6h27.4c2.6 0 4.6 2 4.6 4.6v64z"/></svg></span><span>Home</span><!--[--><!--]--></a></div><div class="navbar-item"><a href="/Knowledge/AI/02.Linear regression.md" class="" aria-label="AI"><!--[--><!--]--><span class="nav-icon"><svg class="ov-icon" style="font-size:1.2em;" aria-hidden="true" width="19.2" height="19.2" viewbox="-1.6 -1.6 19.2 19.2" fill="currentColor"><path d="M6 12.5a.5.5 0 01.5-.5h3a.5.5 0 010 1h-3a.5.5 0 01-.5-.5zM3 8.062C3 6.76 4.235 5.765 5.53 5.886a26.58 26.58 0 004.94 0C11.765 5.765 13 6.76 13 8.062v1.157a.933.933 0 01-.765.935c-.845.147-2.34.346-4.235.346-1.895 0-3.39-.2-4.235-.346A.933.933 0 013 9.219V8.062zm4.542-.827a.25.25 0 00-.217.068l-.92.9a24.767 24.767 0 01-1.871-.183.25.25 0 00-.068.495c.55.076 1.232.149 2.02.193a.25.25 0 00.189-.071l.754-.736.847 1.71a.25.25 0 00.404.062l.932-.97a25.286 25.286 0 001.922-.188.25.25 0 00-.068-.495c-.538.074-1.207.145-1.98.189a.25.25 0 00-.166.076l-.754.785-.842-1.7a.25.25 0 00-.182-.135z"/><path d="M8.5 1.866a1 1 0 10-1 0V3h-2A4.5 4.5 0 001 7.5V8a1 1 0 00-1 1v2a1 1 0 001 1v1a2 2 0 002 2h10a2 2 0 002-2v-1a1 1 0 001-1V9a1 1 0 00-1-1v-.5A4.5 4.5 0 0010.5 3h-2V1.866zM14 7.5V13a1 1 0 01-1 1H3a1 1 0 01-1-1V7.5A3.5 3.5 0 015.5 4h5A3.5 3.5 0 0114 7.5z"/></svg></span><span>AI</span><!--[--><!--]--></a></div><div class="navbar-item"><a href="/Knowledge/note/01.Git Pro.md" class="" aria-label="Note"><!--[--><!--]--><span class="nav-icon"><svg class="ov-icon" style="font-size:1.2em;" aria-hidden="true" width="19.2" height="19.2" viewbox="0 0 512 512" fill="currentColor"><path d="M48 322.3V189.7A29.74 29.74 0 0177.7 160h137.44l24.4-32H77.7A61.77 61.77 0 0016 189.7v132.6A61.77 61.77 0 0077.7 384h96.85a22.57 22.57 0 01.26-7.32l.15-.75.21-.73 6.5-23.2H77.7A29.74 29.74 0 0148 322.3zM386.3 128h-98.64a22.69 22.69 0 01-.27 7.2l-.15.74-.21.73-6.54 23.33H386.3a29.74 29.74 0 0129.7 29.7v132.6a29.74 29.74 0 01-29.7 29.7H247l-24.42 32H386.3a61.77 61.77 0 0061.7-61.7V189.7a61.77 61.77 0 00-61.7-61.7z"/><path d="M162.65 294.16a24.37 24.37 0 01-21.56-13 25 25 0 011.42-25.83l.31-.46.33-.44L197.62 183H89.69a20 20 0 00-20 20v106a20 20 0 0020 20h98.42l9.78-34.86z"/><path d="M276.07 280.89l27.07-35.49a5.2 5.2 0 00.77-1.91 5 5 0 00.08-.66 5 5 0 00-.08-1.29 5.11 5.11 0 00-.68-1.75 4.76 4.76 0 00-.78-.95 3.48 3.48 0 00-.48-.38 4 4 0 00-1.11-.55 4.28 4.28 0 00-1.31-.2h-61.62l12.12-43.21 3.23-11.5 6.21-22.16.51-1.84 7.79-27.76a3.51 3.51 0 00.05-.55v-.16c0-.05 0-.26-.05-.38s0-.09 0-.14a2.2 2.2 0 00-.17-.45 3.77 3.77 0 00-.26-.39l-.09-.1a2.73 2.73 0 00-.25-.23l-.1-.08a3.14 3.14 0 00-.39-.24 2 2 0 00-.41-.14H265.53a2.3 2.3 0 00-.45 0 1.9 1.9 0 00-.42.15l-.13.07-.3.21-.11.1a2.4 2.4 0 00-.36.41l-18 23.63-13.14 17.22-9.85 12.83-63.71 83.55a5.72 5.72 0 00-.44.8 4.78 4.78 0 00-.35 1.09 4.7 4.7 0 00-.08 1.29 4.86 4.86 0 002 3.71 4.74 4.74 0 00.54.31 4.31 4.31 0 001.89.43h61.62L194.42 380.6a3.64 3.64 0 000 .56v.15a2.32 2.32 0 00.06.38.58.58 0 000 .14 2.2 2.2 0 00.17.45 3.62 3.62 0 00.26.38l.09.1.25.24a.39.39 0 01.1.08 2.22 2.22 0 00.39.23 2.83 2.83 0 00.41.14h.13a1.86 1.86 0 00.33 0h.13a2.32 2.32 0 00.45-.06 2.05 2.05 0 00.41-.16l.13-.07.3-.21.11-.09a2.4 2.4 0 00.36-.41L221.82 352l17.53-23z"/><path d="M319.5 256.93l-.46.6L264.51 329h109.8a20 20 0 0020-20V203a20 20 0 00-20-20H274.05l-9.74 34.73h35.24A24.35 24.35 0 01321 230.5a25.21 25.21 0 01-1 25.79zM480 202.67a16 16 0 00-16 16v74.66a16 16 0 0032 0v-74.66a16 16 0 00-16-16z"/></svg></span><span>Note</span><!--[--><!--]--></a></div><div class="navbar-item"><a href="/tags/" class="" aria-label="Tags"><!--[--><!--]--><span class="nav-icon"><svg class="ov-icon" style="font-size:1.2em;" aria-hidden="true" width="19.2" height="19.2" viewbox="-43.52 -43.52 599.04 599.04" fill="currentColor"><path d="M0 252.118V48C0 21.49 21.49 0 48 0h204.118a48 48 0 0133.941 14.059l211.882 211.882c18.745 18.745 18.745 49.137 0 67.882L293.823 497.941c-18.745 18.745-49.137 18.745-67.882 0L14.059 286.059A48 48 0 010 252.118zM112 64c-26.51 0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48z"/></svg></span><span>Tags</span><!--[--><!--]--></a></div><div class="navbar-item"><a href="/about/board.md" class="" aria-label="Board"><!--[--><!--]--><span class="nav-icon"><svg class="ov-icon" style="font-size:1.2em;" aria-hidden="true" width="19.2" height="19.2" viewbox="-1.6 -1.6 19.2 19.2" fill="currentColor"><path d="M4 11a1 1 0 112 0v1a1 1 0 11-2 0v-1zm6-4a1 1 0 112 0v5a1 1 0 11-2 0V7zM7 9a1 1 0 012 0v3a1 1 0 11-2 0V9z"/><path d="M4 1.5H3a2 2 0 00-2 2V14a2 2 0 002 2h10a2 2 0 002-2V3.5a2 2 0 00-2-2h-1v1h1a1 1 0 011 1V14a1 1 0 01-1 1H3a1 1 0 01-1-1V3.5a1 1 0 011-1h1v-1z"/><path d="M9.5 1a.5.5 0 01.5.5v1a.5.5 0 01-.5.5h-3a.5.5 0 01-.5-.5v-1a.5.5 0 01.5-.5h3zm-3-1A1.5 1.5 0 005 1.5v1A1.5 1.5 0 006.5 4h3A1.5 1.5 0 0011 2.5v-1A1.5 1.5 0 009.5 0h-3z"/></svg></span><span>Board</span><!--[--><!--]--></a></div><!--]--><div class="navbar-item"><a style="cursor:pointer;"><span class="nav-icon"><svg class="ov-icon" style="font-size:1.2em;" aria-hidden="true" width="19.2" height="19.2" viewbox="0 0 24 24" fill="currentColor"><path fill="none" d="M0 0h24v24H0z"/><path d="M11 2c4.968 0 9 4.032 9 9s-4.032 9-9 9-9-4.032-9-9 4.032-9 9-9zm0 16c3.867 0 7-3.133 7-7 0-3.868-3.133-7-7-7-3.868 0-7 3.132-7 7 0 3.867 3.132 7 7 7zm8.485.071l2.829 2.828-1.415 1.415-2.828-2.829 1.414-1.414z"/></svg></span><span>Search</span></a></div></nav><!--[--><!--]--><ul class="sidebar-items"><!--[--><li><p tabindex="0" class="sidebar-item sidebar-heading active">Note <!----></p><ul style="" class="sidebar-item-children"><!--[--><li><a href="/Knowledge/note/01.Git%20Pro.html" class="sidebar-item" aria-label="Git Pro"><!--[--><!--]--><!----><span>Git Pro</span><!--[--><!--]--></a><!----></li><li><a href="/Knowledge/note/03.Python%20%E9%9A%8F%E8%AE%B0.html" class="sidebar-item" aria-label="Python 随记"><!--[--><!--]--><!----><span>Python 随记</span><!--[--><!--]--></a><!----></li><li><a href="/Knowledge/note/2023-1-8-Lanqiao.html" class="sidebar-item" aria-label="Lanqiao"><!--[--><!--]--><!----><span>Lanqiao</span><!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/Knowledge/note/2023-01-17-Pytorch.html" class="router-link-active router-link-exact-active router-link-active sidebar-item active" aria-label="Pytorch"><!--[--><!--]--><!----><span>Pytorch</span><!--[--><!--]--></a><ul style="" class="sidebar-item-children"><!--[--><li><a aria-current="page" href="/Knowledge/note/2023-01-17-Pytorch.html#tensor" class="router-link-active router-link-exact-active sidebar-item" aria-label="Tensor"><!--[--><!--]--><!----><span>Tensor</span><!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/Knowledge/note/2023-01-17-Pytorch.html#loss-and-optimizer" class="router-link-active router-link-exact-active sidebar-item" aria-label="Loss And Optimizer"><!--[--><!--]--><!----><span>Loss And Optimizer</span><!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/Knowledge/note/2023-01-17-Pytorch.html#save-and-load" class="router-link-active router-link-exact-active sidebar-item" aria-label="Save And Load"><!--[--><!--]--><!----><span>Save And Load</span><!--[--><!--]--></a><!----></li><!--]--></ul></li><li><a href="/Knowledge/note/Numpy%20%E5%B0%8F%E8%AE%B0.html" class="sidebar-item" aria-label="Numpy 小记"><!--[--><!--]--><!----><span>Numpy 小记</span><!--[--><!--]--></a><!----></li><li><a href="/Knowledge/note/Pandas%20%E5%B0%8F%E8%AE%B0.html" class="sidebar-item" aria-label="Pandas 小记"><!--[--><!--]--><!----><span>Pandas 小记</span><!--[--><!--]--></a><!----></li><!--]--></ul></li><!--]--></ul><!--[--><!--]--></aside><!--]--><div class="page-content"><!--[--><main class="page"><!--[--><div class="article-header" style=""><!----><div class="article-header-content"><!----><h1 class="article-title">Pytorch</h1><!----><div class="article-icons"><div class="article-icon"><svg class="ov-icon" style="font-size:1.2em;" aria-hidden="true" width="19.2" height="19.2" viewbox="-75.52 -43.52 599.04 599.04" fill="currentColor"><path d="M313.6 304c-28.7 0-42.5 16-89.6 16-47.1 0-60.8-16-89.6-16C60.2 304 0 364.2 0 438.4V464c0 26.5 21.5 48 48 48h352c26.5 0 48-21.5 48-48v-25.6c0-74.2-60.2-134.4-134.4-134.4zM400 464H48v-25.6c0-47.6 38.8-86.4 86.4-86.4 14.6 0 38.3 16 89.6 16 51.7 0 74.9-16 89.6-16 47.6 0 86.4 38.8 86.4 86.4V464zM224 288c79.5 0 144-64.5 144-144S303.5 0 224 0 80 64.5 80 144s64.5 144 144 144zm0-240c52.9 0 96 43.1 96 96s-43.1 96-96 96-96-43.1-96-96 43.1-96 96-96z"/></svg><span>Hush</span></div><div class="article-icon"><svg class="ov-icon" style="font-size:1.2em;" aria-hidden="true" width="19.2" height="19.2" viewbox="-75.52 -43.52 599.04 599.04" fill="currentColor"><path d="M400 64h-48V12c0-6.6-5.4-12-12-12h-40c-6.6 0-12 5.4-12 12v52H160V12c0-6.6-5.4-12-12-12h-40c-6.6 0-12 5.4-12 12v52H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h352c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zm-6 400H54c-3.3 0-6-2.7-6-6V160h352v298c0 3.3-2.7 6-6 6z"/></svg><span>2023-01-17</span></div><div class="article-icon"><svg class="ov-icon" style="font-size:1.2em;" aria-hidden="true" width="19.2" height="19.2" viewbox="0 0 24 24" fill="currentColor"><path fill="none" d="M0 0h24v24H0z"/><path d="M17.618 5.968l1.453-1.453 1.414 1.414-1.453 1.453a9 9 0 11-1.414-1.414zM12 20a7 7 0 100-14 7 7 0 000 14zM11 8h2v6h-2V8zM8 1h8v2H8V1z"/></svg><span>3 min</span></div></div></div><!----></div><!--[--><!--]--><!--]--><div class="theme-gungnir-content"><!--[--><!--]--><div><div class="language-python ext-py line-numbers-mode"><pre class="language-python"><code><span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn 
torch<span class="token punctuation">.</span>__version__


<span class="token comment">## Set device type</span>
device <span class="token operator">=</span> <span class="token string">&quot;cuda&quot;</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">&quot;cpu&quot;</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;Using device: </span><span class="token interpolation"><span class="token punctuation">{</span>device<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>

<span class="token comment">## Set the random seed</span>
RANDOM_SEED<span class="token operator">=</span><span class="token number">42</span> 
torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span>seed<span class="token operator">=</span>RANDOM_SEED<span class="token punctuation">)</span> 

<span class="token comment"># Split data into train and test sets</span>
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split
X_train<span class="token punctuation">,</span> X_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span>RANDOM_SEED<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="tensor" tabindex="-1"><a class="header-anchor" href="#tensor" aria-hidden="true">#</a> Tensor</h2><div class="language-python ext-py line-numbers-mode"><pre class="language-python"><code><span class="token comment">## 经典的 tensor 创建方法</span>
torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>data<span class="token punctuation">,</span>dtype<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>device<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>requires_grad<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>pin_memory<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>

<span class="token comment">## 从其他形式转换而来 示例参考：https://pytorch.org/docs/stable/generated/torch.as_tensor.html#torch.as_tensor</span>
torch<span class="token punctuation">.</span>as_tensor<span class="token punctuation">(</span>data<span class="token punctuation">,</span>dtype<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>device<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>ndarray<span class="token punctuation">)</span>

<span class="token comment">## Tensor.ndim</span>
<span class="token comment">## Tensor.shape      # 张量的形状</span>
<span class="token comment">## Tensor.numel		# 张量中元素的总数</span>
torch<span class="token punctuation">.</span>mm<span class="token punctuation">(</span>tensor_A<span class="token punctuation">,</span>tensor_B<span class="token punctuation">)</span>    <span class="token comment">## 矩阵乘法</span>
<span class="token comment">## 变形</span>
torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> shape<span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>T<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>    <span class="token comment">## 只针对2D tensor转置</span>
torch<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> dim0<span class="token punctuation">,</span> dim1<span class="token punctuation">)</span> <span class="token comment">##交换两个维度</span>

torch<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> out<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span> <span class="token comment">## 去除那些维度大小为1的维度</span>
torch<span class="token punctuation">.</span>unbind<span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>		<span class="token comment">## 去除某个维度</span>
torch<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> dim<span class="token punctuation">,</span> out<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span>		<span class="token comment">## 在指定位置添加维度。</span>


<span class="token comment">## 将多个张量连结起来</span>

torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>A<span class="token punctuation">,</span>B<span class="token punctuation">)</span><span class="token punctuation">,</span>dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>   <span class="token comment">## 在行方向上</span>
torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>A<span class="token punctuation">,</span>B<span class="token punctuation">)</span><span class="token punctuation">,</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>   <span class="token comment">## 在列方向上</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="loss-and-optimizer" tabindex="-1"><a class="header-anchor" href="#loss-and-optimizer" aria-hidden="true">#</a> Loss And Optimizer</h2><ul><li>PyTorch在 <code>torch.nn</code> 中有很多内置的损失函数。</li><li><code>torch.optim</code> 中找到各种优化函数实现。</li></ul><div class="language-python ext-py line-numbers-mode"><pre class="language-python"><code><span class="token comment"># Create the loss function</span>
loss_fn <span class="token operator">=</span> nn<span class="token punctuation">.</span>L1Loss<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># MAE loss is same as L1Loss</span>

<span class="token comment"># Create the optimizer</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>params<span class="token operator">=</span>model_0<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment"># parameters of target model to optimize</span>
                            lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span> <span class="token comment"># learning rate (how much the optimizer should change parameters at each step, higher=more (less stable), lower=less (might take a long time))</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>trainng</li></ul><img src="https://cdn.jsdelivr.net/gh/crush598/image@main/AI202302121620749.png" alt="01-pytorch-training-loop-annotated" style="zoom:50%;"><ul><li>testing</li></ul><img src="https://cdn.jsdelivr.net/gh/crush598/image@main/AI202302121620559.png" alt="01-pytorch-testing-loop-annotated" style="zoom:50%;"><h2 id="save-and-load" tabindex="-1"><a class="header-anchor" href="#save-and-load" aria-hidden="true">#</a> Save And Load</h2><ul><li>torch.save()</li></ul><div class="language-python ext-py line-numbers-mode"><pre class="language-python"><code><span class="token keyword">from</span> pathlib <span class="token keyword">import</span> Path

<span class="token comment"># 1. Create models directory </span>
MODEL_PATH <span class="token operator">=</span> Path<span class="token punctuation">(</span><span class="token string">&quot;models&quot;</span><span class="token punctuation">)</span>
MODEL_PATH<span class="token punctuation">.</span>mkdir<span class="token punctuation">(</span>parents<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> exist_ok<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment"># 2. Create model save path </span>
MODEL_NAME <span class="token operator">=</span> <span class="token string">&quot;01_pytorch_workflow_model_0.pth&quot;</span>
MODEL_SAVE_PATH <span class="token operator">=</span> MODEL_PATH <span class="token operator">/</span> MODEL_NAME

<span class="token comment"># 3. Save the model state dict </span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;Saving model to: </span><span class="token interpolation"><span class="token punctuation">{</span>MODEL_SAVE_PATH<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>obj<span class="token operator">=</span>model_0<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment"># only saving the state_dict() only saves the models learned parameters</span>
           f<span class="token operator">=</span>MODEL_SAVE_PATH<span class="token punctuation">)</span> 
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>Torch.load()</li></ul><div class="language-python ext-py line-numbers-mode"><pre class="language-python"><code><span class="token comment"># Instantiate a fresh instance of LinearRegressionModelV2</span>
loaded_model_1 <span class="token operator">=</span> LinearRegressionModelV2<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># Load model state dict </span>
loaded_model_1<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>MODEL_SAVE_PATH<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># Put model to target device (if your data is on GPU, model will have to be on GPU to make predictions)</span>
loaded_model_1<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;Loaded model:\n</span><span class="token interpolation"><span class="token punctuation">{</span>loaded_model_1<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;Model on device:\n</span><span class="token interpolation"><span class="token punctuation">{</span><span class="token builtin">next</span><span class="token punctuation">(</span>loaded_model_1<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>device<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></div><!--[--><!--]--></div><footer class="page-meta"><!----><!----><!----></footer><nav class="page-nav"><p class="inner"><span class="prev"><a href="/Knowledge/note/2023-1-8-Lanqiao.html" class="" aria-label="Lanqiao"><!--[--><!--]--><!----><span>Lanqiao</span><!--[--><!--]--></a></span><span class="next"><a href="/Knowledge/note/Numpy%20%E5%B0%8F%E8%AE%B0.html" class="" aria-label="Numpy 小记"><!--[--><!--]--><!----><span>Numpy 小记</span><!--[--><!--]--></a></span></p></nav><!--[--><!--]--><!----></main><!--]--></div><div class="search-page" role="search"><span class="search-close"><svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 448 512" width="28" height="28" fill="currentColor"><path d="M224 416c-8.188 0-16.38-3.125-22.62-9.375l-192-192c-12.5-12.5-12.5-32.75 0-45.25s32.75-12.5 45.25 0L224 338.8l169.4-169.4c12.5-12.5 32.75-12.5 45.25 0s12.5 32.75 0 45.25l-192 192C240.4 412.9 232.2 416 224 416z"></path></svg></span><div class="gungnir-search-box"><input placeholder="$ grep ..." autocomplete="off" spellcheck="false" value><!----></div></div><div class="menu-btn-container"><div class="menu-btn-wrapper"><div class="menu-btn"><div style="" class="menu-btn-icon"><span></span><span></span><span></span></div><div style="display:none;" class="menu-text">0</div><svg class="menu-progress"><circle class="menu-border" cx="50%" cy="50%" r="48%" style="stroke-dasharray:0% 314.15926%;"></circle></svg></div><div class="menu-btn-child-wrapper"><div title="toggle color mode" class="menu-btn-child"><svg class="ov-icon" style="font-size:1.2em;display:none;" aria-hidden="true" width="19.2" height="19.2" viewbox="-43.52 -43.52 599.04 599.04" fill="currentColor"><path d="M256 160c-52.9 0-96 43.1-96 96s43.1 96 96 96 96-43.1 96-96-43.1-96-96-96zm246.4 80.5l-94.7-47.3 33.5-100.4c4.5-13.6-8.4-26.5-21.9-21.9l-100.4 33.5-47.4-94.8c-6.4-12.8-24.6-12.8-31 0l-47.3 94.7L92.7 70.8c-13.6-4.5-26.5 8.4-21.9 21.9l33.5 100.4-94.7 47.4c-12.8 6.4-12.8 24.6 0 31l94.7 47.3-33.5 100.5c-4.5 13.6 8.4 26.5 21.9 21.9l100.4-33.5 47.3 94.7c6.4 12.8 24.6 12.8 31 0l47.3-94.7 100.4 33.5c13.6 4.5 26.5-8.4 21.9-21.9l-33.5-100.4 94.7-47.3c13-6.5 13-24.7.2-31.1zm-155.9 106c-49.9 49.9-131.1 49.9-181 0-49.9-49.9-49.9-131.1 0-181 49.9-49.9 131.1-49.9 181 0 49.9 49.9 49.9 131.1 0 181z"/></svg><svg class="ov-icon" style="font-size:1.2em;display:none;" aria-hidden="true" width="19.2" height="19.2" viewbox="-43.52 -43.52 599.04 599.04" fill="currentColor"><path d="M283.211 512c78.962 0 151.079-35.925 198.857-94.792 7.068-8.708-.639-21.43-11.562-19.35-124.203 23.654-238.262-71.576-238.262-196.954 0-72.222 38.662-138.635 101.498-174.394 9.686-5.512 7.25-20.197-3.756-22.23A258.156 258.156 0 00283.211 0c-141.309 0-256 114.511-256 256 0 141.309 114.511 256 256 256z"/></svg><svg class="ov-icon" style="font-size:1.2em;" aria-hidden="true" width="19.2" height="19.2" viewbox="-43.52 -43.52 599.04 599.04" fill="currentColor"><path d="M224 96l16-32 32-16-32-16-16-32-16 32-32 16 32 16 16 32zM80 160l26.66-53.33L160 80l-53.34-26.67L80 0 53.34 53.33 0 80l53.34 26.67L80 160zm352 128l-26.66 53.33L352 368l53.34 26.67L432 448l26.66-53.33L512 368l-53.34-26.67L432 288zm70.62-193.77L417.77 9.38C411.53 3.12 403.34 0 395.15 0c-8.19 0-16.38 3.12-22.63 9.38L9.38 372.52c-12.5 12.5-12.5 32.76 0 45.25l84.85 84.85c6.25 6.25 14.44 9.37 22.62 9.37 8.19 0 16.38-3.12 22.63-9.37l363.14-363.15c12.5-12.48 12.5-32.75 0-45.24zM359.45 203.46l-50.91-50.91 86.6-86.6 50.91 50.91-86.6 86.6z"/></svg></div><div class="menu-btn-child"><svg class="ov-icon" style="font-size:1.2em;" aria-hidden="true" width="19.2" height="19.2" viewbox="-75.52 -43.52 599.04 599.04" fill="currentColor"><path d="M207.029 381.476L12.686 187.132c-9.373-9.373-9.373-24.569 0-33.941l22.667-22.667c9.357-9.357 24.522-9.375 33.901-.04L224 284.505l154.745-154.021c9.379-9.335 24.544-9.317 33.901.04l22.667 22.667c9.373 9.373 9.373 24.569 0 33.941L240.971 381.476c-9.373 9.372-24.569 9.372-33.942 0z"/></svg></div><div class="menu-btn-child"><svg class="ov-icon" style="font-size:1.2em;" aria-hidden="true" width="19.2" height="19.2" viewbox="-75.52 -43.52 599.04 599.04" fill="currentColor"><path d="M240.971 130.524l194.343 194.343c9.373 9.373 9.373 24.569 0 33.941l-22.667 22.667c-9.357 9.357-24.522 9.375-33.901.04L224 227.495 69.255 381.516c-9.379 9.335-24.544 9.317-33.901-.04l-22.667-22.667c-9.373-9.373-9.373-24.569 0-33.941L207.03 130.525c9.372-9.373 24.568-9.373 33.941-.001z"/></svg></div><!----><div class="toggle-sidebar-button menu-btn-child menu-btn-sidebar" title="toggle sidebar" aria-expanded="false" role="button" tabindex="0"><svg class="ov-icon" style="font-size:1.2em;" aria-hidden="true" width="19.2" height="19.2" viewbox="-1.6 -1.6 19.2 19.2" fill="currentColor"><path d="M14 2a1 1 0 011 1v10a1 1 0 01-1 1H2a1 1 0 01-1-1V3a1 1 0 011-1h12zM2 1a2 2 0 00-2 2v10a2 2 0 002 2h12a2 2 0 002-2V3a2 2 0 00-2-2H2z"/><path d="M3 4a1 1 0 011-1h2a1 1 0 011 1v8a1 1 0 01-1 1H4a1 1 0 01-1-1V4z"/></svg></div></div></div></div><!----></div><!--]--></div>
    <script type="module" src="/assets/app.aed97a80.js" defer></script>
  </body>
</html>
